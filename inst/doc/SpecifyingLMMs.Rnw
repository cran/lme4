\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{amsmath}
\usepackage{bm}
\usepackage[authoryear,round]{natbib}
\bibliographystyle{plainnat}
\DefineVerbatimEnvironment{Sinput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontshape=sl,
  fontfamily=courier,fontseries=b, fontsize=\scriptsize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontfamily=courier,fontseries=b,%
  fontsize=\scriptsize}
%%\VignetteIndexEntry{Specifying LMMs}
%%\VignetteDepends{lme4}
\title{Specifying linear mixed models in lme4}
\author{Douglas Bates\\Department of Statistics\\%
  University of Wisconsin -- Madison}
\begin{document}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,strip.white=TRUE}
\SweaveOpts{include=TRUE}
\setkeys{Gin}{width=\textwidth}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\package}[1]{\textsf{\small{#1}}}
\maketitle
\begin{abstract}
  A linear mixed model to be fit by \code{lmer} is specified by a
  formula.  The fixed-effects terms in this formula are
  interpreted as they would be in the \code{lm} or \code{glm} functions.  In
  this vignette we describe the interpretation of the random effects
  terms in these formulas and provide several examples of fitted models and their
  formulas.
\end{abstract}
\newcommand{\Bv}{\ensuremath{\bm{\mathcal{B}}}}
%\newcommand{\R}{\texttt{R}}
\newcommand{\Yv}{\ensuremath{\bm{\mathcal{Y}}}}
<<preliminaries,echo=FALSE,print=FALSE>>=
options(width=80, show.signif.stars = FALSE,
        lattice.theme = function() canonical.theme("pdf", color = FALSE))
library(lattice)
library(Matrix)
library(lme4)
#data("Rail", package = "MEMSS")
#data("ScotsSec", package = "mlmRev")
@

\section{Introduction}
\label{sec:intro}

We begin with examples of data sets to which we will fit some linear
mixed models.  Once we have some examples to bear in mind we will
describe the mathematical formulation of the model and how the formula
describing the model in \code{lmer} is interpreted.

\section{Examples of data sets and models}
\label{sec:examples}

\citet{Davies:1972} is a classic reference on the use of statistics in
the chemical industry.  The first edition was published in 1947.
Although we refer to the chapters and pages in the fourth edition, published
in 1972, the discussion of these data sets and models to be fit to
them does go back to 1947 and earlier.

\subsection{The Dyestuff example}
\label{sec:Dyestuff}

The \code{Dyestuff} data in the \package{lme4} package, shown in
Figure~\ref{fig:Dyestuff}, 
\begin{figure}[tb]
  \centering
<<Dyestuff,fig=TRUE,width=8,height=3,echo=FALSE>>=  
print(dotplot(reorder(Batch, Yield) ~ Yield, Dyestuff,
              ylab = "Batch", jitter.y = TRUE, aspect = 0.3,
              type = c("p", "a")))
@ 
\caption{Dotplot of the data from the dyestuff example described in
  Davies, 1972.  The six batches of the intermediate product determine
  the row.  Within each row the yields for the five preparations from
  that batch are shown.  The points have been jittered slightly on the
  vertical axis to prevent overplotting.  Because there is no
  indication of a preferred ordering for the batches (such as a time
  ordering) we reorder the batches according to increasing mean yield.
  The line joins the mean yields of the batches.}
  \label{fig:Dyestuff}
\end{figure}
are described in Example 6.1 of \citep[p. 130]{Davies:1972} as coming
from
\begin{quote}
  an investigation to find out how much the variation from batch to
  batch in the quality of an intermediate product (H-acid) contributes
  to the variation of the yield of a dyestuff (Napthalene Black 12B)
  made from it.  In the experiment six samples of the intermediate,
  representing different batches of works manufacture, were obtained,
  and five preparations of dyestuff were made in the laboratory from
  each sample.  The equivalent yield of each preparation as grams of
  standard color was determined by dye-trial, $\dots$
\end{quote}

Note that the purpose of the experiment is to characterize the
variation in the quality of the product that can be attributed to the
batch to batch variation of the intermediate product.  The yield is
the response and the batch is the covariate.  Batch is a
\emph{categorical} covariate, in the sense that the information about
the batch is simply whether the sample was created from the first
batch or the second batch or so on.  We can take any of the 30
observed yields and categorize it as having been prepared from one
of the six batches of intermediate.

The \emph{factor} data type in \texttt{R} provides a representation for such
categorical covariates.  In contrast, the yield is a numerical
response measured on a physically meaningful scale (grams) and we
represent that as a numerical value.
<<strDyestuff>>=
str(Dyestuff)
@ 

We say that there are six \emph{levels} of the \code{Batch} covariate.
When incorporating categorical covariates like \code{Batch} in a
linear statistical model we obtain numerical values for the
\emph{effects} of the different levels.  We can see from
Figure~\ref{fig:Dyestuff} that batch F had the lowest mean yield and
batch E had the highest mean yield so in our model we expect to see a
low effect for batch F and a high effect for batch F.

We distinguish between the effects of factors with a fixed and
reproducible set of levels, such as the sex of a participant in a
experiment on human or animal subjects, and those of factors for which
the observed set of levels can change throughout the experiment or
study.  These are, not surprisingly, called \emph{fixed effects} and
\emph{random effects}, respectively.  In a way these terms are
misleading because it is the set of levels of the factor associated
with the effects that we determine to be fixed or random, not the
effects per se.  Nevertheless, these terms are widely used and hence
we adopt them.

We employ fixed effects and random effects terms in a statistical
model for different purposes.  Because a fixed-effects term is
associated with a fixed set of levels for a factor, we want to
estimate the effect of those particular levels.  Often we also want to
contrast the effects of particular levels of the factor.  In a
clinical trial, for example, some patients may receive Drug A, some
may receive Drug B and some may receive a placebo. Typically the
purpose of the trial is to contrast the effects of specific drugs or
to compare the effects on patients a particular drug versus a placebo.

In a random-effects term the effects of particular levels of the
factor are not of as much interest to us as is the amount of variation
in the response that can be attributed to the different levels of the
factor.  This is exactly the situation in this dyestuff experiment.
The batches that were examined are but a sample of the batches that
could be or have been produced.  For the purposes of predicting future
yields we are not interested in the effects of past batches, which may
already have been used up, as we are in the effects of future, as yet
unobserved, batches.  We can't know exactly what their levels may be
but we can characterize the batch to batch variability that we have
seen and base our predictions on that.

A \emph{mixed-effects} model is a statistical model that incorporates
fixed-effects parameters and random effects.  As we shall see in
\S\ref{sec:Prob}, the mathematical formulation of random effects that
we use requires that there always be at least one fixed effect in the
model.  That is, in our formulation any model that incorporates random
effects is a mixed-effects model.

We can fit a linear mixed-effects model to the response \code{Yield}
in the \code{Dyestuff} data incorporating random effects for the
\code{Batch} factor, save the fitted model as \code{Dm1} then
summarize it with
<<Dyestufflmer>>=
summary(Dm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff))
@ 

\subsection{The Dyestuff model formula}
\label{sec:Dyestuffformula}

The \code{lmer} function (the name, pronounced like ``Elmer'', is an
acronym for Linear Mixed-Effects in R) follows the convention of most
model fitting functions in \texttt{R} that the first two arguments are
\code{formula}, a formula describing the model, and \code{data}, the
optional name of a data frame in which the formula can be evaluated.

The formula for model \code{Dm1}
<<Dyestuffformula,echo=FALSE>>=
Yield ~ 1 + (1|Batch)
@ 
can be read as ``\code{Yield} is modeled by a constant plus a constant
given \code{Batch}''.  This formula consists of two \emph{terms},
\code{1} and \code{(1|Batch)}.  In general, terms in the model are
separated by plus signs (\code{+}).  A term incorporating the vertical
bar character (\code{|}) is a random-effects term.  A term without the
vertical bar is a fixed-effects term.

There is a single fixed-effects term, \code{1}, in this formula.  A
model matrix, which we will write as $\bm X$, is created by evaluating
all the fixed-effects terms in the formula using the data frame and
stored in the slot named \code{X} in the fitted model.  In this case
$\bm X$ is a trivial model matrix with 30 rows and one column.  All of
the elements of $\bm X$ are unity.  The first three rows of this matrix are
<<Dm1Xmat>>=
head(Dm1@X, n = 3)
@ 

The single random-effects term in this formula is \code{(1|Batch)}. In
a random-effects term the expression on the right hand side of the
vertical bar must evaluate to a factor.  Typically it is simply the
name of a factor, like \code{Batch} here, but more general expressions
are possible.  The expression on the left hand side in the data frame
as a linear model formula, producing a model matrix.  In this case the
model matrix from the left hand side is the same as $\bm X$.  It has
one column and 30 rows.

\section{Mathematical formulation of the model}


A linear mixed-effects model (LMM) is statistical model similar to the
conventional linear model (also called a linear regression model).  In
both types of models we consider a set of observed responses, which we
shall write as the $n$-dimensional vector $\bm y$, and associated
values of other variables, which we shall call \emph{covariates}.
These models are linear in the sense that we express the effect of
the covariates in terms of \emph{model matrices}.

For example, a linear model is frequently written
\begin{equation}
  \label{eq:lm}
  \bm y = \bm X\bm\beta + \bm\epsilon,\quad\bm\epsilon\sim\mathcal{N}(\bm
  0,\sigma^2\bm I)
\end{equation}
where $\bm\beta$ is a $p$-dimensional parameter vector, $\bm X$ is an
$n\times p$ model matrix derived from the model formula and the
observed values of the covariates, and $\bm\epsilon$ is the random
noise, or unexplained variation, in the observations.  As indicated in
(\ref{eq:lm}) we typically begin with the assumption 
that $\bm\epsilon\sim\mathcal{N}(\bm 0,\sigma^2\bm I)$.  That is, the
noise is assumed to have a multivariate normal (or ``Gaussian'')
distribution with mean $\bm 0$ and variance-covariance matrix
$\sigma^2\bm I_n$ where $\bm I_n$ is the identity matrix of size $n$.

Writing a linear model as (\ref{eq:lm}) blurs the distinction between
the random variable $\Yv$ and its observed value $\bm y$.  Because
this distinction is important in describing LMMs we will rewrite the
linear model (\ref{eq:lm}) as
\begin{equation}
  \label{eq:lm2}
  \Yv\sim\mathcal{N}\left(\bm X\bm\beta, \sigma^2\bm I_n\right)
\end{equation}


\subsection{Probability distribution formulation of LMMs}
\label{sec:Prob}


A linear mixed-effects model incorporates fixed-effects parameters and
random effects.  Technically, the random effects are unobserved random
variables, which we will write as the random vector $\Bv$, while the
fixed-effects parameters are indeed parameters.  We will write them as
$\bm\beta$.  The random variable representing the response is $\Yv$
with observed value $\bm y$.  For a linear mixed model, the
conditional distribution of $\Yv$, given $\Bv=\bm b$, is a
multivariate normal (or ``Gaussian'') distribution with (conditional)
mean $\bm X\bm\beta+\bm Z\bm b$ and variance-covariance matrix
$\sigma^2\bm I_n$ where $n$ is the number of observations (the
dimension of $\bm y$) and the notation $\bm I_n$ indicates the
$n\times n$ identity matrix of size $n$.  The fixed-effects parameter
vector $\bm\beta$ is of dimension $p$ and its model matrix $\bm X$ is
$n\times p$.  The random effects are of dimension $q$ and their model
matrix $\bm Z$ is $n\times q$.

\begin{equation}
  \label{eq:condresp}
  \left(\Yv|\Bv=\bm b\right)\sim
  \mathcal{N}\left(\bm X\bm\beta+\bm Z\bm b,\sigma^2\bm I_n\right)
\end{equation}

The distribution of $\Bv$ is also assumed to be multivariate normal,
this time with mean $\bm 0$ and a $q\times q$ symmetric
variance-covariance matrix that we will write as
$\sigma^2\bm\Sigma(\bm\theta)$ where $\sigma^2$ is the same parameter
used in the variance-covariance of $\Yv|\Bv=\bm b$ and $\bm\Sigma$ is
a $q\times q$ \emph{relative variance matrix} for the random effects.
The notation $\bm\Sigma(\bm\theta)$ indicates that $\bm\Sigma$ depends
on a parameter vector $\bm\theta$.  Typically the dimension of
$\bm\theta$ is much, much smaller than $q$, the size of $\bm\Sigma$.

The model matrices $\bm X$ and $\bm Z$, the form of $\bm\Sigma$ and
how $\bm\Sigma$ depends on $\bm\theta$ are all specified by the
formula which is the first argument to \code{lmer}.  
\end{document}
